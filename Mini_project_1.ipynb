{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkontorousis/ECSE326-project-group4/blob/master/Mini_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "aj41cpfd-kSq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qB5r5_sIDZwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a41d9b-75cf-4362-b7ba-4c6c0fd32e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "v8wqyYYj-857"
      },
      "outputs": [],
      "source": [
        "path ='/content/drive/My Drive/Colab Notebooks/ML/'\n",
        "\n",
        "housing = pd.read_csv(path + 'boston.csv')\n",
        "\n",
        "wine = pd.read_csv(path + 'wine.csv', header = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL-91haTrBhO"
      },
      "source": [
        "## Task 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDSQBSiHDQfo",
        "outputId": "7e951a91-1587-4897-8f03-671e3e3259ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 14) (506, 14)\n"
          ]
        }
      ],
      "source": [
        "print(wine.shape,\n",
        "housing.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1rGpaw7B7Ae",
        "outputId": "68649491-ae6b-4d36-9fbd-c3d50141eea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRIM       0\n",
            "ZN         0\n",
            "INDUS      0\n",
            "CHAS       0\n",
            "NOX        0\n",
            "RM         0\n",
            "AGE        0\n",
            "DIS        0\n",
            "RAD        0\n",
            "TAX        0\n",
            "PTRATIO    0\n",
            "B          0\n",
            "LSTAT      0\n",
            "MEDV       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(housing.isna().sum()) # isna checks if any data is missing, and sum counts the number of missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "h68oaPn0UVlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9b5bac-bf91-4b5d-98dc-d4b4ad3af936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(wine.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4Rm0AkmQU_dh"
      },
      "outputs": [],
      "source": [
        "#print(pd.to_numeric(housing[i], 'raise') for i in range (1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "mABMO4bKY1Rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2e13ac-f32a-4b18-ab92-418308c23488"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRIM       float64\n",
              "ZN         float64\n",
              "INDUS      float64\n",
              "CHAS         int64\n",
              "NOX        float64\n",
              "RM         float64\n",
              "AGE        float64\n",
              "DIS        float64\n",
              "RAD          int64\n",
              "TAX        float64\n",
              "PTRATIO    float64\n",
              "B          float64\n",
              "LSTAT      float64\n",
              "MEDV       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "housing.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "cGcmsYYYcWTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cabbe02-566c-42fa-c5da-8970411ec93d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       int64\n",
              "1     float64\n",
              "2     float64\n",
              "3     float64\n",
              "4     float64\n",
              "5       int64\n",
              "6     float64\n",
              "7     float64\n",
              "8     float64\n",
              "9     float64\n",
              "10    float64\n",
              "11    float64\n",
              "12    float64\n",
              "13      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "wine.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2sI4b49bcjBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b440f9b8-606c-4d24-e77e-10c99a1129c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "del housing['B']\n",
        "housing.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "JBBAr8J9nKBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c037cb3-b9bb-4e9b-e0cd-51dc9e93fb0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
            "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
            "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
            "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
            "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
            "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
            "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
            "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
            "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
            "\n",
            "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
            "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
            "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
            "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
            "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
            "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
            "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
            "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
            "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
            "\n",
            "             MEDV  \n",
            "count  506.000000  \n",
            "mean    22.532806  \n",
            "std      9.197104  \n",
            "min      5.000000  \n",
            "25%     17.025000  \n",
            "50%     21.200000  \n",
            "75%     25.000000  \n",
            "max     50.000000  \n"
          ]
        }
      ],
      "source": [
        "print(housing.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hdq5xRCfy_qY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ca8fd7-0cd4-4db9-8107-6ce75dbbfcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               0           1           2           3           4           5   \\\n",
            "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
            "mean     1.938202   13.000618    2.336348    2.366517   19.494944   99.741573   \n",
            "std      0.775035    0.811827    1.117146    0.274344    3.339564   14.282484   \n",
            "min      1.000000   11.030000    0.740000    1.360000   10.600000   70.000000   \n",
            "25%      1.000000   12.362500    1.602500    2.210000   17.200000   88.000000   \n",
            "50%      2.000000   13.050000    1.865000    2.360000   19.500000   98.000000   \n",
            "75%      3.000000   13.677500    3.082500    2.557500   21.500000  107.000000   \n",
            "max      3.000000   14.830000    5.800000    3.230000   30.000000  162.000000   \n",
            "\n",
            "               6           7           8           9           10          11  \\\n",
            "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
            "mean     2.295112    2.029270    0.361854    1.590899    5.058090    0.957449   \n",
            "std      0.625851    0.998859    0.124453    0.572359    2.318286    0.228572   \n",
            "min      0.980000    0.340000    0.130000    0.410000    1.280000    0.480000   \n",
            "25%      1.742500    1.205000    0.270000    1.250000    3.220000    0.782500   \n",
            "50%      2.355000    2.135000    0.340000    1.555000    4.690000    0.965000   \n",
            "75%      2.800000    2.875000    0.437500    1.950000    6.200000    1.120000   \n",
            "max      3.880000    5.080000    0.660000    3.580000   13.000000    1.710000   \n",
            "\n",
            "               12           13  \n",
            "count  178.000000   178.000000  \n",
            "mean     2.611685   746.893258  \n",
            "std      0.709990   314.907474  \n",
            "min      1.270000   278.000000  \n",
            "25%      1.937500   500.500000  \n",
            "50%      2.780000   673.500000  \n",
            "75%      3.170000   985.000000  \n",
            "max      4.000000  1680.000000  \n"
          ]
        }
      ],
      "source": [
        "print(wine.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3bui2Z2r1mKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3506480a-6bad-4d34-fe99-8e85dd401f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Housing Data \n",
            "                  0             1             2             3             4   \\\n",
            "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
            "mean  -1.685082e-16  2.194117e-18 -8.021690e-16 -1.755293e-17 -2.113373e-15   \n",
            "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
            "min   -4.197819e-01 -4.877224e-01 -1.557842e+00 -2.725986e-01 -1.465882e+00   \n",
            "25%   -4.109696e-01 -4.877224e-01 -8.676906e-01 -2.725986e-01 -9.130288e-01   \n",
            "50%   -3.906665e-01 -4.877224e-01 -2.110985e-01 -2.725986e-01 -1.442174e-01   \n",
            "75%    7.396560e-03  4.877224e-02  1.015999e+00 -2.725986e-01  5.986790e-01   \n",
            "max    9.933931e+00  3.804234e+00  2.422565e+00  3.668398e+00  2.732346e+00   \n",
            "\n",
            "                 5             6             7             8             9   \\\n",
            "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
            "mean  -2.643472e-15 -6.740326e-16  1.590296e-15  4.914821e-17 -7.021173e-18   \n",
            "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
            "min   -3.880249e+00 -2.335437e+00 -1.267069e+00 -9.828429e-01 -1.313990e+00   \n",
            "25%   -5.686303e-01 -8.374480e-01 -8.056878e-01 -6.379618e-01 -7.675760e-01   \n",
            "50%   -1.084655e-01  3.173816e-01 -2.793234e-01 -5.230014e-01 -4.646726e-01   \n",
            "75%    4.827678e-01  9.067981e-01  6.623709e-01  1.661245e+00  1.530926e+00   \n",
            "max    3.555044e+00  1.117494e+00  3.960518e+00  1.661245e+00  1.798194e+00   \n",
            "\n",
            "                 10            11          12  \n",
            "count  5.060000e+02  5.060000e+02  506.000000  \n",
            "mean   6.175122e-15 -5.511621e-16   22.532806  \n",
            "std    1.000990e+00  1.000990e+00    9.197104  \n",
            "min   -2.707379e+00 -1.531127e+00    5.000000  \n",
            "25%   -4.880391e-01 -7.994200e-01   17.025000  \n",
            "50%    2.748590e-01 -1.812536e-01   21.200000  \n",
            "75%    8.065758e-01  6.030188e-01   25.000000  \n",
            "max    1.638828e+00  3.548771e+00   50.000000   \n",
            "\n",
            "Normalized Wine Data \n",
            "                0             1             2             3             4   \\\n",
            "count  178.000000  1.780000e+02  1.780000e+02  1.780000e+02  1.780000e+02   \n",
            "mean     1.938202  1.447531e-14 -8.582398e-16 -8.283012e-16 -6.486696e-17   \n",
            "std      0.775035  1.002821e+00  1.002821e+00  1.002821e+00  1.002821e+00   \n",
            "min      1.000000 -2.434235e+00 -1.432983e+00 -3.679162e+00 -2.671018e+00   \n",
            "25%      1.000000 -7.882448e-01 -6.587486e-01 -5.721225e-01 -6.891372e-01   \n",
            "50%      2.000000  6.099988e-02 -4.231120e-01 -2.382132e-02  1.518295e-03   \n",
            "75%      3.000000  8.361286e-01  6.697929e-01  6.981085e-01  6.020883e-01   \n",
            "max      3.000000  2.259772e+00  3.109192e+00  3.156325e+00  3.154511e+00   \n",
            "\n",
            "                 5             6             7             8             9   \\\n",
            "count  1.780000e+02  1.780000e+02  1.780000e+02  1.780000e+02  1.780000e+02   \n",
            "mean  -2.993860e-17 -3.991813e-17  7.983626e-17 -2.326479e-15 -5.164408e-16   \n",
            "std    1.002821e+00  1.002821e+00  1.002821e+00  1.002821e+00  1.002821e+00   \n",
            "min   -2.088255e+00 -2.107246e+00 -1.695971e+00 -1.868234e+00 -2.069034e+00   \n",
            "25%   -8.244151e-01 -8.854682e-01 -8.275393e-01 -7.401412e-01 -5.972835e-01   \n",
            "50%   -1.222817e-01  9.595986e-02  1.061497e-01 -1.760948e-01 -6.289785e-02   \n",
            "75%    5.096384e-01  8.089974e-01  8.490851e-01  6.095413e-01  6.291754e-01   \n",
            "max    4.371372e+00  2.539515e+00  3.062832e+00  2.402403e+00  3.485073e+00   \n",
            "\n",
            "                 10            11            12            13  \n",
            "count  1.780000e+02  1.780000e+02  1.780000e+02  1.780000e+02  \n",
            "mean   5.987720e-17  1.666582e-15  2.178033e-15 -1.297339e-16  \n",
            "std    1.002821e+00  1.002821e+00  1.002821e+00  1.002821e+00  \n",
            "min   -1.634288e+00 -2.094732e+00 -1.895054e+00 -1.493188e+00  \n",
            "25%   -7.951025e-01 -7.675624e-01 -9.522483e-01 -7.846378e-01  \n",
            "50%   -1.592246e-01  3.312687e-02  2.377348e-01 -2.337204e-01  \n",
            "75%    4.939560e-01  7.131644e-01  7.885875e-01  7.582494e-01  \n",
            "max    3.435432e+00  3.301694e+00  1.960915e+00  2.971473e+00  \n"
          ]
        }
      ],
      "source": [
        "def normalize(X, i): # i is the index of the true value column\n",
        "  rand_ind = np.random.choice(X.shape[0], X.shape[0], replace = False) # makes an array of n indices from 0 to N\n",
        "  X = X[rand_ind]\n",
        "  Y = X[:,i]\n",
        "  X = (X-np.mean(X, 0))/(np.std(X, 0))\n",
        "  X[:,i] = Y\n",
        "\n",
        "  return (X)\n",
        "\n",
        "def normalize2(data, true_value_col_index):\n",
        "  rand_ind = np.random.choice(data.shape[0], data.shape[0], replace = False)\n",
        "  X = data[rand_ind]\n",
        "  Y = data[:,true_value_col_index]\n",
        "  X = (data/data.max(0))\n",
        "  X[:,true_value_col_index] = Y\n",
        "  return (X)\n",
        "\n",
        "housing_norm1 = normalize(housing.values, -1)\n",
        "wine_norm1 = normalize(wine.values, 0)\n",
        "\n",
        "housing_pd = pd.DataFrame(housing_norm1)\n",
        "wine_pd = pd.DataFrame(wine_norm1)\n",
        "\n",
        "print ('Normalized Housing Data \\n', housing_pd.describe(), '\\n')\n",
        "print ('Normalized Wine Data \\n', wine_pd.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "M1xWdVcIztOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaf441e-6557-4d9d-d86f-27f448360d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Housing Data \n",
            "                0           1           2           3           4           5   \\\n",
            "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
            "mean     0.040612    0.113636    0.401470    0.069170    0.636849    0.715790   \n",
            "std      0.096672    0.233225    0.247309    0.253994    0.133040    0.080025   \n",
            "min      0.000071    0.000000    0.016583    0.000000    0.442021    0.405581   \n",
            "25%      0.000922    0.000000    0.187094    0.000000    0.515499    0.670330   \n",
            "50%      0.002883    0.000000    0.349315    0.000000    0.617681    0.707118   \n",
            "75%      0.041327    0.125000    0.652487    0.000000    0.716418    0.754385   \n",
            "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "\n",
            "               6           7           8           9           10          11  \\\n",
            "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
            "mean     0.685749    0.312954    0.397892    0.574173    0.838888    0.333238   \n",
            "std      0.281489    0.173645    0.362802    0.237042    0.098407    0.188071   \n",
            "min      0.029000    0.093151    0.041667    0.263010    0.572727    0.045562   \n",
            "25%      0.450250    0.173189    0.166667    0.392405    0.790909    0.183039   \n",
            "50%      0.775000    0.264499    0.208333    0.464135    0.865909    0.299184   \n",
            "75%      0.940750    0.427858    1.000000    0.936709    0.918182    0.446537   \n",
            "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "\n",
            "               12  \n",
            "count  506.000000  \n",
            "mean    22.532806  \n",
            "std      9.197104  \n",
            "min      5.000000  \n",
            "25%     17.025000  \n",
            "50%     21.200000  \n",
            "75%     25.000000  \n",
            "max     50.000000   \n",
            "\n",
            "Normalized Wine Data \n",
            "                0           1           2           3           4           5   \\\n",
            "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
            "mean     1.938202    0.876643    0.402819    0.732668    0.649831    0.615689   \n",
            "std      0.775035    0.054742    0.192611    0.084936    0.111319    0.088163   \n",
            "min      1.000000    0.743763    0.127586    0.421053    0.353333    0.432099   \n",
            "25%      1.000000    0.833614    0.276293    0.684211    0.573333    0.543210   \n",
            "50%      2.000000    0.879973    0.321552    0.730650    0.650000    0.604938   \n",
            "75%      3.000000    0.922286    0.531466    0.791796    0.716667    0.660494   \n",
            "max      3.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "\n",
            "               6           7           8           9           10          11  \\\n",
            "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
            "mean     0.591524    0.399463    0.548264    0.444385    0.389084    0.559912   \n",
            "std      0.161302    0.196626    0.188566    0.159877    0.178330    0.133668   \n",
            "min      0.252577    0.066929    0.196970    0.114525    0.098462    0.280702   \n",
            "25%      0.449098    0.237205    0.409091    0.349162    0.247692    0.457602   \n",
            "50%      0.606959    0.420276    0.515152    0.434358    0.360769    0.564327   \n",
            "75%      0.721649    0.565945    0.662879    0.544693    0.476923    0.654971   \n",
            "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
            "\n",
            "               12          13  \n",
            "count  178.000000  178.000000  \n",
            "mean     0.652921    0.444579  \n",
            "std      0.177498    0.187445  \n",
            "min      0.317500    0.165476  \n",
            "25%      0.484375    0.297917  \n",
            "50%      0.695000    0.400893  \n",
            "75%      0.792500    0.586310  \n",
            "max      1.000000    1.000000  \n"
          ]
        }
      ],
      "source": [
        "housing_norm2 = normalize2(housing.values, -1)\n",
        "wine_norm2 = normalize2(wine.values, 0)\n",
        "\n",
        "housing_pd2 = pd.DataFrame(housing_norm2)\n",
        "wine_pd2 = pd.DataFrame(wine_norm2)\n",
        "\n",
        "print ('Normalized Housing Data \\n', housing_pd2.describe(), '\\n')\n",
        "print ('Normalized Wine Data \\n', wine_pd2.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo1P-s3hq76K"
      },
      "source": [
        "## Task 2: Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swx-snZfgHLI"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "oGCJ_r_dnfGU"
      },
      "outputs": [],
      "source": [
        "# Simplify\n",
        "def bias(X):\n",
        "\n",
        "  bias = np.ones((X.shape[0],1))\n",
        "\n",
        "  y = np.hstack((bias, X))\n",
        "  return(y)\n",
        "\n",
        "\n",
        "class LinReg():\n",
        "    def __init__(self, data, verbose = True):\n",
        "        self.X = data\n",
        "        self.trainingTime = 0         # holds the training time of the last run of self.fit()\n",
        "        self.verbose = verbose        # used for logging to stdout\n",
        "\n",
        "    def log(self, message):\n",
        "      if self.verbose:\n",
        "        print(message)\n",
        "\n",
        "    def getModelType(self, batch_size):\n",
        "      if batch_size == self.X.shape[0]:\n",
        "        return \"GD\"\n",
        "      elif batch_size == 0:\n",
        "        return \"Analytical\"\n",
        "      else:\n",
        "        return \"SGD\"\n",
        "\n",
        "    def fit(self, batch_size = 0, lr = 0.1, type = 0):\n",
        "      '''Performs the linear modelling of the data this instance of LinReg is initialized with.\n",
        "      If type = 0 then it performs analytical linear regression\n",
        "      If type = 1 then it performs lineare regression with GD\n",
        "      If type = 2 then it performs linear regression with SGD'''\n",
        "\n",
        "      X = self.X[:, 0:-1]\n",
        "      X = bias(X)\n",
        "\n",
        "      Y = self.X[:, -1]\n",
        "\n",
        "      if batch_size == 0 and type == 0: # solve for w using w = (X_T@X)^-1X_T@y\n",
        "        start_time = time.time()\n",
        "        self.w = np.linalg.solve(X.T@X,X.T@Y) # From linear Regression notes, X.T@X@w = X.T@Y which is in the form Aw = b, use linalg to solve it so we avoid taking the inverse\n",
        "        end_time = time.time()\n",
        "        elapsed_time = (end_time - start_time)  * 1000\n",
        "        self.trainingTime = elapsed_time\n",
        "        self.log(f\"[Analytical] Training time: {elapsed_time} ms.\\n\")\n",
        "        return (self.w)\n",
        "\n",
        "      else: # (Stochastic) Gradient descent\n",
        "        # if the batch size is equal to the shape of the data, then it effectively computes\n",
        "        # the simple gradient descent, as all of the data is selected\n",
        "        n = batch_size if type != 1 else X.shape[0]\n",
        "        N = X.shape[0]\n",
        "        w = np.zeros(X.shape[1]) # We know x has 13 features, but this is more general\n",
        "        g = np.inf\n",
        "        i = 0\n",
        "        error_history = []\n",
        "        start_time = time.time()\n",
        "        while np.linalg.norm(g) > 1e-2 and i < 1000000:\n",
        "          rand_ind = np.random.choice(N, n, replace = False) # makes an array of n indices from 0 to N\n",
        "          x = X[rand_ind] #creates a new matrix using the random indices\n",
        "          y = Y[rand_ind]\n",
        "          yh = np.dot(x,w)\n",
        "          g = np.dot(x.T, yh - y)/n\n",
        "          w = w - lr*g\n",
        "          i += 1\n",
        "          error = np.mean((yh - y) ** 2)\n",
        "          error_history.append(error)\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        self.w = w\n",
        "\n",
        "        if (type == 1):\n",
        "          self.log(\"Running linear regression with GD\")\n",
        "        else:\n",
        "          self.log(f\"Running linear regression with SGD with batch size {n}\")\n",
        "        self.log(f\"Learning rate {lr} | Training time: {elapsed_time} ms\")\n",
        "        self.log(f\"Converged to a MSE of {error} in {i} iterations.\")\n",
        "        if (self.verbose):\n",
        "          plt.plot(error_history)\n",
        "          plt.xlabel(\"Iterations\")\n",
        "          plt.ylabel(\"Mean Squared Error [MSE]\")\n",
        "          plt.title(\"MSE vs. Iterations\")\n",
        "          plt.show()\n",
        "        return (self.w)\n",
        "\n",
        "\n",
        "    def predict(self, X, w):\n",
        "      # We want to predict the median value.\n",
        "      X = bias(X[:, 0:-1])\n",
        "      y = np.dot(X,w)\n",
        "      return(y)\n",
        "\n",
        "    def error(self, test_set = None, batch_size = 0, lr = 0.1):\n",
        "      if test_set is None:\n",
        "        test_set = self.X\n",
        "\n",
        "      true_val = test_set[:, -1]\n",
        "      predicted = self.predict(test_set, batch_size, lr)\n",
        "\n",
        "      return (true_val - predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXc5aCccTrSm"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "HskPFg_V4Rkl"
      },
      "outputs": [],
      "source": [
        "def softmax(logits):\n",
        "    # Subtract the maximum value along the specified axis for numerical stability\n",
        "    max_logits = np.max(logits, axis=1, keepdims=True)\n",
        "    shifted_logits = logits - max_logits\n",
        "\n",
        "    # Compute the softmax probabilities along the specified axis\n",
        "    exp_logits = np.exp(shifted_logits)\n",
        "    softmax_probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "\n",
        "    return softmax_probs\n",
        "\n",
        "\n",
        "class LogReg():\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.X = data\n",
        "    self.row = data.shape[0]\n",
        "    self.col = data.shape[1]\n",
        "\n",
        "  def fit(self, batch_size = 0, lr = 0.1):\n",
        "    X = self.X[:, 1:]\n",
        "    X = bias(X)\n",
        "\n",
        "    Y = self.X[:, 0]\n",
        "    y = np.zeros((self.row, 3))\n",
        "    y[np.arange(self.row), Y.astype(int) - 1] = 1 # Sets category 1 as [1,0,0], 2 as [0,1,0] and 3 as [0,0,1]\n",
        "\n",
        "\n",
        "    if batch_size == 0:\n",
        "      batch_size = self.row\n",
        "\n",
        "    w = np.random.rand(X.shape[1], 3)\n",
        "    start_time = time.time()\n",
        "    g = np.inf\n",
        "    count = 0\n",
        "    while np.linalg.norm(g) > 1e-3 and count < 1000000:\n",
        "      rand_ind = np.random.choice(self.row, batch_size, replace = False) # makes an array of n indices from 0 to N\n",
        "      x = X[rand_ind] #creates a new matrix using the random indices\n",
        "      y_batch = y[rand_ind]\n",
        "      z = np.dot(x,w)\n",
        "      yh = softmax(z)\n",
        "\n",
        "      g = np.dot(x.T, yh - y_batch)/batch_size\n",
        "      w = w - lr*g\n",
        "      count += 1\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"[GD with batch size {batch_size} and learning rate {lr}] Training time: {elapsed_time} seconds.\\nConverged in {count} iterations.\\n\")\n",
        "    return (w)\n",
        "\n",
        "\n",
        "  def predict(self, X, w):\n",
        "      X = X[:, 1:]\n",
        "      X = bias(X)\n",
        "      z = np.dot(X,w)\n",
        "      yh = softmax(z)\n",
        "      y = np.argmax(z,1)+1\n",
        "      return (y)\n",
        "\n",
        "  def error(self, X, w):\n",
        "    true_val = X[:, 0]\n",
        "    predicted = self.predict(X, w)\n",
        "    return (true_val - predicted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udc9EEv9rQJN"
      },
      "source": [
        "## Task 3: Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo1fpBCJmcV8"
      },
      "source": [
        "###3.1 80/20 Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV7SafbBwMzV"
      },
      "source": [
        "#### 3.1.1 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "HYdmn2foaY3Y"
      },
      "outputs": [],
      "source": [
        "#Split housing dataset into an 80/20 training and testing set\n",
        "n = int(housing.shape[0]//(1/0.8))\n",
        "housing_train = housing_norm2[0:n]\n",
        "housing_test = housing_norm2[n:]\n",
        "house = LinReg(housing_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "aUl-mQ8uWN7w",
        "outputId": "0ea84347-3aa0-4228-cc0f-69fa6c55a2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Analytical] Training time: 2.9947757720947266 ms.\n",
            "\n",
            "Running linear regression with SGD with batch size 404\n",
            "Learning rate 0.1 | Training time: 2.3156137466430664 ms\n",
            "Converged to a MSE of 22.843709776875333 in 9546 iterations.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training the model\n",
        "analytical_model = house.fit();\n",
        "gd_model = house.fit(n, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "N6VcIqM92eHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f9ef73-55f5-4d78-8c57-f3bd45db09b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Metric      Analytical (Train)    Analytical (Test)    GD (Train)    GD (Test) \n",
            "\n",
            " MAE                    3.30727              4.57002       3.27463      4.54641 \n",
            "\n",
            " MSE                   22.7836              30.5565       22.8437      30.554   \n",
            "\n",
            " RMSE                   4.77322              5.5278        4.77951      5.52757 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Metrics for Linear Regression\n",
        "\n",
        "def mae(true, pred):\n",
        "    n = len(true)\n",
        "    abs_errors = [np.abs(true - pred)]\n",
        "    mae = np.sum(abs_errors) / n\n",
        "    return mae\n",
        "\n",
        "def mse(true, pred):\n",
        "    n = len(true)\n",
        "    squared_errors = [(true - pred)**2]\n",
        "    mse = np.sum(squared_errors) / n\n",
        "    return mse\n",
        "\n",
        "def rmse(true, pred):\n",
        "    n = len(true)\n",
        "    squared_errors = [(true - pred)**2]\n",
        "    rmse = np.sqrt(np.sum(squared_errors) / n)\n",
        "    return rmse\n",
        "\n",
        "#---------------- MAE ------------------------------------------------------------\n",
        "analytical_mae_train = mae(housing_train[:, -1], house.predict(housing_train, analytical_model))\n",
        "analytical_mae_test = mae(housing_test[:, -1], house.predict(housing_test, analytical_model))\n",
        "\n",
        "gd_mae_train = mae(housing_train[:, -1], house.predict(housing_train, gd_model))\n",
        "gd_mae_test = mae(housing_test[:, -1], house.predict(housing_test, gd_model))\n",
        "\n",
        "#---------------- MSE ------------------------------------------------------------\n",
        "analytical_mse_train = mse(housing_train[:, -1], house.predict(housing_train, analytical_model))\n",
        "analytical_mse_test = mse(housing_test[:, -1], house.predict(housing_test, analytical_model))\n",
        "\n",
        "gd_mse_train = mse(housing_train[:, -1], house.predict(housing_train, gd_model))\n",
        "gd_mse_test = mse(housing_test[:, -1], house.predict(housing_test, gd_model))\n",
        "\n",
        "#---------------- RMSE ------------------------------------------------------------\n",
        "\n",
        "analytical_rmse_train = rmse(housing_train[:, -1], house.predict(housing_train, analytical_model))\n",
        "analytical_rmse_test = rmse(housing_test[:, -1], house.predict(housing_test, analytical_model))\n",
        "\n",
        "gd_rmse_train = rmse(housing_train[:, -1], house.predict(housing_train, gd_model))\n",
        "gd_rmse_test = rmse(housing_test[:, -1], house.predict(housing_test, gd_model))\n",
        "\n",
        "# Create a table\n",
        "data = [[\"Metric\", \"Analytical (Train)\", \"Analytical (Test)\", \"GD (Train)\", \"GD (Test)\"],\n",
        "        [\"MAE\", analytical_mae_train, analytical_mae_test, gd_mae_train, gd_mae_test],\n",
        "        [\"MSE\", analytical_mse_train, analytical_mse_test, gd_mse_train, gd_mse_test],\n",
        "        [\"RMSE\", analytical_rmse_train, analytical_rmse_test, gd_rmse_train, gd_rmse_test]]\n",
        "\n",
        "table = tabulate(data, headers=\"firstrow\", tablefmt=\"fancy_grid\")\n",
        "\n",
        "# Print the table\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KLbaMwWweFW"
      },
      "source": [
        "#### 3.1.2 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "N4CFuDURm7Vt"
      },
      "outputs": [],
      "source": [
        "#Split wine dataset into an 80/20 training and testing set\n",
        "m = int(wine.shape[0]//(1/0.8))\n",
        "wine_train = wine_norm2[0:m]\n",
        "wine_test = wine_norm2[m:]\n",
        "wine_model = LogReg(wine_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "JyJqTVpBnoAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181618de-d3c2-4896-8fe4-5c924661b3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GD with batch size 142 and learning rate 0.1] Training time: 14.921810626983643 seconds.\n",
            "Converged in 133781 iterations.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Training the model\n",
        "model = wine_model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taLg9WuXmwCw",
        "outputId": "0a18544c-a38c-40c4-9372-efd3d7b4d8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy (%): 1.0\n",
            "Testing Accuracy (%): 1.0\n",
            "\n",
            "C1 Training Precision: 1.0, C2 Training Precision: 1.0, C3 Training Precision: 1.0, Average Training Precision: 1.0\n",
            "C1 Testing Precision: nan, C2 Testing Precision: nan, C3 Testing Precision: 1.0, Average Testing Precision: nan\n",
            "\n",
            "C1 Training Recall: 1.0, C2 Training Recall: 1.0, C3 Training Recall: 1.0, Average Training Recall: 1.0\n",
            "C1 Testing Recall: nan, C2 Testing Recall: nan, C3 Testing Recall: 1.0, Average Testing Recall: nan\n",
            "\n",
            "C1 Training F1-score: 1.0, C2 Training F1-score: 1.0, C3 Training F1-score: 1.0, Average Training F1-score: 1.0\n",
            "C1 Testing F1-score: nan, C2 Testing F1-score: nan, C3 Testing F1-score: 1.0, Average Testing F1-score: nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-8140c31ec34b>:9: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  p1 = T1/(T1 + F1)\n",
            "<ipython-input-73-8140c31ec34b>:14: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  p2 = T2/(T2 + F2)\n",
            "<ipython-input-73-8140c31ec34b>:28: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  r1 = T1/cat1\n",
            "<ipython-input-73-8140c31ec34b>:33: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  r2 = T2/cat2\n"
          ]
        }
      ],
      "source": [
        "#Metrics for Logistic Regression\n",
        "def accuracy(error):\n",
        "  return(np.count_nonzero(error == 0)/error.shape[0])\n",
        "\n",
        "def precision(true_val, predicted):\n",
        "  T1 = np.sum((np.array(true_val) == 1) & (np.array(predicted) == 1))\n",
        "  F1 = np.sum((np.array(true_val) != 1) & (np.array(predicted) == 1))\n",
        "\n",
        "  p1 = T1/(T1 + F1)\n",
        "\n",
        "  T2 = np.sum((np.array(true_val) == 2) & (np.array(predicted) == 2))\n",
        "  F2 = np.sum((np.array(true_val) != 2) & (np.array(predicted) == 2))\n",
        "\n",
        "  p2 = T2/(T2 + F2)\n",
        "\n",
        "  T3 = np.sum((np.array(true_val) == 3) & (np.array(predicted) == 3))\n",
        "  F3 = np.sum((np.array(true_val) != 3) & (np.array(predicted) == 3))\n",
        "\n",
        "  p3 = T3/(T3 + F3)\n",
        "\n",
        "  return(p1, p2, p3, (p1 + p2 + p3)/3)\n",
        "\n",
        "def recall(true_val, predicted):\n",
        "\n",
        "  T1 = np.sum((np.array(true_val) == 1) & (np.array(predicted) == 1))\n",
        "  cat1 = np.count_nonzero(true_val == 1)\n",
        "\n",
        "  r1 = T1/cat1\n",
        "\n",
        "  T2 = np.sum((np.array(true_val) == 2) & (np.array(predicted) == 2))\n",
        "  cat2 = np.count_nonzero(true_val == 2)\n",
        "\n",
        "  r2 = T2/cat2\n",
        "\n",
        "  T3 = np.sum((np.array(true_val) == 3) & (np.array(predicted) == 3))\n",
        "  cat3 = np.count_nonzero(true_val == 3)\n",
        "\n",
        "  r3 = T3/cat3\n",
        "\n",
        "  return(r1, r2, r3, (r1+r2+r3)/3)\n",
        "\n",
        "def F1(true_val, predicted):\n",
        "    p1,p2,p3,p = precision(true_val, predicted)\n",
        "    r1,r2,r3,r = recall(true_val, predicted)\n",
        "\n",
        "    F1_1 = 2*p1*r1/(r1+p1)\n",
        "    F1_2 = 2*p2*r2/(r2+p2)\n",
        "    F1_3 = 2*p3*r3/(r3+p3)\n",
        "    F1 = 2*p*r/(r+p)\n",
        "\n",
        "    return(F1_1, F1_2, F1_3, F1)\n",
        "\n",
        "\n",
        "acc_train = accuracy(wine_model.error(wine_train, model))\n",
        "acc_test = accuracy(wine_model.error(wine_test, model))\n",
        "print(f\"Training Accuracy (%): {acc_train}\")\n",
        "print(f\"Testing Accuracy (%): {acc_test}\\n\")\n",
        "\n",
        "p1_train, p2_train, p3_train, pavg_train = precision(wine_train[:, 0], wine_model.predict(wine_train, model))\n",
        "p1_test, p2_test, p3_test, pavg_test = precision(wine_test[:, 0], wine_model.predict(wine_test, model))\n",
        "print(f\"C1 Training Precision: {p1_train}, C2 Training Precision: {p2_train}, C3 Training Precision: {p3_train}, Average Training Precision: {pavg_train}\")\n",
        "print(f\"C1 Testing Precision: {p1_test}, C2 Testing Precision: {p2_test}, C3 Testing Precision: {p3_test}, Average Testing Precision: {pavg_test}\\n\")\n",
        "\n",
        "r1_train, r2_train, r3_train, ravg_train = recall(wine_train[:, 0], wine_model.predict(wine_train, model))\n",
        "r1_test, r2_test, r3_test, ravg_test = recall(wine_test[:, 0], wine_model.predict(wine_test, model))\n",
        "print(f\"C1 Training Recall: {r1_train}, C2 Training Recall: {r2_train}, C3 Training Recall: {r3_train}, Average Training Recall: {ravg_train}\")\n",
        "print(f\"C1 Testing Recall: {r1_test}, C2 Testing Recall: {r2_test}, C3 Testing Recall: {r3_test}, Average Testing Recall: {ravg_test}\\n\")\n",
        "\n",
        "f1_train, f2_train, f3_train, favg_train = F1(wine_train[:, 0], wine_model.predict(wine_train, model))\n",
        "f1_test, f2_test, f3_test, favg_test = F1(wine_test[:, 0], wine_model.predict(wine_test, model))\n",
        "print(f\"C1 Training F1-score: {f1_train}, C2 Training F1-score: {f2_train}, C3 Training F1-score: {f3_train}, Average Training F1-score: {favg_train}\")\n",
        "print(f\"C1 Testing F1-score: {f1_test}, C2 Testing F1-score: {f2_test}, C3 Testing F1-score: {f3_test}, Average Testing F1-score: {favg_test}\\n\")\n",
        "\n",
        "# Create a table using tabulate\n",
        "table_data = [\n",
        "    [\"Metric\", \"Class 1\", \"Class 2\", \"Class 3\", \"Average\"],\n",
        "    [\"Accuracy (%)\", acc_train, \"-\", \"-\", \"-\"],\n",
        "    [\"\", acc_test, \"-\", \"-\", \"-\"],\n",
        "    [\"Precision\", p1_train, p2_train, p3_train, pavg_train],\n",
        "    [\"\", p1_test, p2_test, p3_test, pavg_test],\n",
        "    [\"Recall\", r1_train, r2_train, r3_train, ravg_train],\n",
        "    [\"\", r1_test, r2_test, r3_test, ravg_test],\n",
        "    [\"F1-score\", f1_train, f2_train, f3_train, favg_train],\n",
        "    [\"\", f1_test, f2_test, f3_test, favg_test]\n",
        "]\n",
        "\n",
        "# Print the table\n",
        "# print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"fancy_grid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73SXFNvlmgfT"
      },
      "source": [
        "###3.2 Five-fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ewEU6eeTS4By"
      },
      "outputs": [],
      "source": [
        "def five_fold_split(training_data):\n",
        "  '''Returns a list of 5 tuples (training_set, validation_set) each for every fold chosen as the validation fold'''\n",
        "  m = training_data.shape[0]\n",
        "\n",
        "  m = n // 5*4\n",
        "  test = data[m:]\n",
        "\n",
        "  training = data[:m]\n",
        "  j = m // 5\n",
        "\n",
        "  set1, set2, set3, set4, set5 = training[:j], training[j:2*j], training[2*j:3*j], training[3*j:4*j], training[4*j:5*j]\n",
        "\n",
        "  t1, v1 = np.vstack((set1, set2, set3, set4)), set5\n",
        "  t2, v2 = np.vstack((set1, set2, set3, set5)), set4\n",
        "  t3, v3 = np.vstack((set1, set2, set4, set5)), set3\n",
        "  t4, v4 = np.vstack((set1, set3, set4, set5)), set2\n",
        "  t5, v5 = np.vstack((set2, set3, set4, set5)), set1\n",
        "\n",
        "  folds = [(t1, v1), (t2, v2), (t3, v3), (t4, v4), (t5, v5)]\n",
        "\n",
        "  return folds\n",
        "\n",
        "def train_test_split(data):\n",
        "  '''Splits the data into a 80/20 train/test split.\n",
        "  Returns a tuple (train, test) of the two data set splits'''\n",
        "\n",
        "  n = data.shape[0]\n",
        "  m = n // 5 * 4\n",
        "\n",
        "  test = data[m:]\n",
        "  training = data[:m]\n",
        "\n",
        "  return training, test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def five_fold_linreg(data, type=0, lr=0.1, batch_size=0):\n",
        "  '''Performs five-fold cross validation with the given learning rate.\n",
        "  Returns a tuple (metrics, avg_mse) where avg_mse := average mean squared error and metrics is a pandas Dataframe with all the metrics for this run\n",
        "\n",
        "  Data: The data to use for performing five-fold cross-validation. Expected to be normalized\n",
        "\n",
        "  Type: used to choose between analytical linear regression (0), linear regression with GD (1)\n",
        "    and linear regression with SGD (2)\n",
        "\n",
        "  lr: learning rate, used only when performing linear regression with GD\n",
        "\n",
        "\n",
        "  '''\n",
        "\n",
        "  training_data, test_data = train_test_split(data)\n",
        "  five_folds = five_fold_split(training_data)\n",
        "\n",
        "  Mae = np.zeros(5)\n",
        "  Mse = np.zeros(5)\n",
        "  Rmse = np.zeros(5)\n",
        "  Std = np.zeros(5)\n",
        "  Max = np.zeros(5)\n",
        "  trainingTimes = np.zeros(5)\n",
        "\n",
        "  if (type not in [0, 1, 2]):\n",
        "    raise ValueError(\"Invalid type provided! Analytical (0), GD (1) or SGD (2) are allowed\")\n",
        "  elif (type == 2 and batch_size == 0):\n",
        "    raise ValueError(\"Cannot perform SGD with a batch size of 0!\")\n",
        "  for i in range(len(five_folds)):\n",
        "    training_set, validation_set = five_folds[i]\n",
        "    regression = LinReg(training_set, False)\n",
        "    w = regression.fit(batch_size=batch_size, lr=lr, type=type)\n",
        "    yh = regression.predict(validation_set, w)\n",
        "    y = validation_set[:,-1]\n",
        "\n",
        "    Mae[i] = mae(y, yh)\n",
        "    Mse[i] = mse(y, yh)\n",
        "    Rmse[i] = rmse(y, yh)\n",
        "    Std[i] = np.std(y-yh)\n",
        "    Max[i] = np.max(y-yh)\n",
        "    trainingTimes[i] = regression.trainingTime\n",
        "\n",
        "  print(Mae)\n",
        "\n",
        "  avg_mae = np.mean(Mae)\n",
        "  avg_mse = np.mean(Mse)\n",
        "  avg_rmse = np.mean(Rmse)\n",
        "  avg_std = np.mean(Std)\n",
        "  avg_max = np.mean(Max)\n",
        "  avg_training_times = np.mean(trainingTimes)\n",
        "\n",
        "  metrics = np.hstack((np.arange(1, 6).reshape((5, 1)), Mae.reshape(5,1), Mse.reshape(5,1), Rmse.reshape(5,1), Std.reshape(5,1), Max.reshape(5,1), trainingTimes.reshape(5, 1)))\n",
        "  metrics = np.vstack((metrics, ['Means of Folds', avg_mae, avg_mse, avg_rmse, avg_std, avg_max, avg_training_times]))\n",
        "\n",
        "  df_metrics = pd.DataFrame(metrics, columns=['#Fold', 'Mean Absolute Error', 'Mean Squared Error', 'Root Mean Squared Error', 'Standard Deviation of the Error', 'Maximum Error', 'Training Time'])\n",
        "\n",
        "  return df_metrics, avg_mse\n"
      ],
      "metadata": {
        "id": "-8LL6p0PGfFt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "sp0BUGY3DwaM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "9ac88a08-5c72-4b38-e5c1-f3888cba788a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-fbabcd997e3b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Analytical linreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfive_fold_linreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing_norm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing Five-Fold Cross-Validation for Analytical Linear Regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'keys'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtablefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fancy_grid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-374621b487ca>\u001b[0m in \u001b[0;36mfive_fold_linreg\u001b[0;34m(data, type, lr, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mfive_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfive_fold_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mMae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-bef4b40ad85b>\u001b[0m in \u001b[0;36mfive_fold_split\u001b[0;34m(training_data)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mt3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 5 and the array at index 1 has size 0"
          ]
        }
      ],
      "source": [
        "# Analytical linreg\n",
        "results, _ = five_fold_linreg(housing_norm2, type=0, lr=0.1)\n",
        "print(\"Performing Five-Fold Cross-Validation for Analytical Linear Regression\")\n",
        "print(tabulate(results, headers='keys', tablefmt=\"fancy_grid\"))\n",
        "print(f\"\\n\\n\")\n",
        "\n",
        "# GD linreg\n",
        "results, _ = five_fold_linreg(housing_norm2, type=1, lr=0.1)\n",
        "print(f\"Performing Five-Fold Cross-Validation for Linear Regression with GD with Learning Rate = {0.1}\")\n",
        "print(tabulate(results, headers='keys', tablefmt=\"fancy_grid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecAjk3PxseSy"
      },
      "outputs": [],
      "source": [
        "def logistic_validation(data, batch_size, lr):\n",
        "  batch, fold, j = split(data, 0)\n",
        "\n",
        "  acc = np.zeros(5)\n",
        "  pre = np.zeros(5)\n",
        "  pre1 = np.zeros(5)\n",
        "  pre2 = np.zeros(5)\n",
        "  pre3 = np.zeros(5)\n",
        "  rec = np.zeros(5)\n",
        "  rec1 = np.zeros(5)\n",
        "  rec2 = np.zeros(5)\n",
        "  rec3 = np.zeros(5)\n",
        "  f1 = np.zeros(5)\n",
        "  f1_1 = np.zeros(5)\n",
        "  f1_2 = np.zeros(5)\n",
        "  f1_3 = np.zeros(5)\n",
        "\n",
        "  for i in range (5):\n",
        "    training_set = batch[i*fold: (i+1)*fold - j]\n",
        "    validation_set = batch[(i+1)*fold - j: (i+1)*fold]\n",
        "\n",
        "    regression = LogReg(training_set)\n",
        "    w = regression.fit(batch_size, lr)\n",
        "    yh = regression.predict(validation_set, w)\n",
        "    y = validation_set[:,0]\n",
        "\n",
        "    acc[i] = accuracy(y-yh)\n",
        "    pre1[i], pre2[i], pre3[i], pre[i] = precision(y, yh)\n",
        "    rec1[i],rec2[i], rec3[i], rec[i] = recall(y, yh)\n",
        "    f1_1[i], f1_2[i], f1_3[i], f1[i]  =  F1(y, yh)\n",
        "\n",
        "    avg_acc = np.mean(acc)\n",
        "    avg_pre1 = np.mean(pre1)\n",
        "    avg_pre2 = np.mean(pre2)\n",
        "    avg_pre3 = np.mean(pre3)\n",
        "    avg_pre = np.mean(pre)\n",
        "    avg_rec1 = np.mean(rec1)\n",
        "    avg_rec2 = np.mean(rec2)\n",
        "    avg_rec3 = np.mean(rec3)\n",
        "    avg_rec = np.mean(rec)\n",
        "    avg_f1_1 = np.mean(f1_1)\n",
        "    avg_f1_2 = np.mean(f1_2)\n",
        "    avg_f1_3 = np.mean(f1_3)\n",
        "    avg_f1 = np.mean(f1)\n",
        "\n",
        "  #metrics = np.hstack((acc.reshape(5,1), pre1.reshape(5,1), pre2.reshape(5,1), pre3.reshape(5,1),pre.reshape(5,1), rec1.reshape(5,1), rec2.reshape(5,1), rec3.reshape(5,1), rec.reshape(5,1), f1_1.reshape(5,1), f1_2.reshape(5,1), f1_3.reshape(5,1), f1.reshape(5,1)))\n",
        "\n",
        "  #Metrics = pd.DataFrame(metrics, columns=['Accuracy', 'Precision Category 1', 'Precision Category 2', 'Precision Category 3', 'Average Precision', 'Recall Category 1', 'Recall Category 2', 'Recall Category 3', 'Average Recall', 'F1-Score Category 1', 'F1-Score Category 2', 'F1-Score Category 3', 'Average F1-Score'])\n",
        "\n",
        "  print (f'Logistic Regression Performance for a Batch Size of {batch_size}, and a Learning Rate of {lr} \\n')\n",
        "  print (f'The Average Accuracy is: {avg_acc}\\n')\n",
        "  print (f'The Average Precision in Category 1 is: {avg_pre1}\\n')\n",
        "  print (f'The Average Precision in Category 2 is:{avg_pre2}\\n')\n",
        "  print (f'The Average Precision in Category 3 is: {avg_pre3}\\n')\n",
        "  print (f'The Average Mean Precision is: {avg_pre}\\n')\n",
        "  print (f'The Average Recall in Category 1 is: {avg_rec1}\\n')\n",
        "  print (f'The Average Recall in Category 2 is: {avg_rec1}\\n')\n",
        "  print (f'The Average Recall in Category 3 is: {avg_rec1}\\n')\n",
        "  print (f'The Average Mean Recall is: {avg_rec}\\n')\n",
        "  print (f'The Average F1-Score in Category 1 is: {avg_f1_1}\\n')\n",
        "  print (f'The Average F1-Score in Category 2 is: {avg_f1_2}\\n')\n",
        "  print (f'The Average F1-Score in Category 3 is: {avg_f1_3}\\n')\n",
        "  print (f'The Average Mean F1-Score is: {avg_f1}\\n')\n",
        "\n",
        "\n",
        "logistic_validation(wine_norm2, 0, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "towsMQIsTj8j"
      },
      "source": [
        "###3.3 Growing Subsets of Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouaIClhh621K"
      },
      "outputs": [],
      "source": [
        "house_train_performance = []\n",
        "house_test_performance = []\n",
        "wine_train_performance = []\n",
        "wine_test_performance = []\n",
        "train_sizes = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "\n",
        "for size in train_sizes:\n",
        "  n = int(housing_train.shape[0]//(1/size))\n",
        "  housing_train_fraction = housing_train[0:n]\n",
        "  house = LinReg(housing_train_fraction)\n",
        "  model = house.fit(n, 0.1)\n",
        "  mse_train = mse(housing_train[0:n, -1], house.predict(housing_train_fraction, model))\n",
        "  mse_test = mse(housing_test[:, -1], house.predict(housing_test, model))\n",
        "  house_train_performance.append(mse_train)\n",
        "  house_test_performance.append(mse_test)\n",
        "\n",
        "print()\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, house_train_performance, marker='o', label='Training MSE')\n",
        "plt.plot(train_sizes, house_test_performance, marker='o', label='Test MSE')\n",
        "plt.xlabel('Training Size (Fraction of Data)')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.title('Effect of Training Size on Model Performance\\n[Housing Dataset - Linear Regression]')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "for size in train_sizes:\n",
        "  n = int(wine_train.shape[0]//(1/size))\n",
        "  wine_train_fraction = wine_train[0:n]\n",
        "  wine_model = LogReg(wine_train_fraction)\n",
        "  model = wine_model.fit()\n",
        "  acc_train = accuracy(wine_model.error(wine_train_fraction, model))\n",
        "  acc_test = accuracy(wine_model.error(wine_test, model))\n",
        "  wine_train_performance.append(acc_train)\n",
        "  wine_test_performance.append(acc_test)\n",
        "\n",
        "print()\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, wine_train_performance, marker='o', label='Training Accuracy')\n",
        "plt.plot(train_sizes, wine_test_performance, marker='o', label='Test Accuracy')\n",
        "plt.xlabel('Training Size (Fraction of Data)')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Effect of Training Size on Model Performance\\n[Wine Dataset - Logistic Regression]')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAP4vgWlGfu1"
      },
      "source": [
        "### 3.4 Growing Mini-Batch Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2hpaEXSD9lt"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 8, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0P06SeKEp-c"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 16, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dvoD-NpGXIO"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4GmYh4HInq5"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 64, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWTeJfXEKgPj"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 128, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-45nBGgMMOTL"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 256, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnICpisOOldy"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 8, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm3A9lO5xgwt"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 16, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WNC37tTxuzc"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6KCT1h8yKcz"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 64, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R4obnpdyyjd"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 100, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIvAW6aoZQAY"
      },
      "outputs": [],
      "source": [
        "lin_batch = [8, 16, 32, 64, 128, 256]\n",
        "avg_time = [70.2685, 72.0082, 74.20, 74.9227, 77.0533, 81.4199]\n",
        "avg_mse = [23.8758, 24.5152, 23.5456, 24.2011, 27.1282, 24.6170]\n",
        "avg_mae = [3.444, 3.5402, 3.4044, 3.4248, 3.6187, 3.5948]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lin_batch, avg_time, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('Average Time [s]')\n",
        "plt.title('Average Training Time vs Minibatch Size for LinReg with Using 5-Fold Cross Validation [alpha = 0.1, 1-mil iterations]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lin_batch, avg_mse, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Average Mean Squared Error vs Minibatch Size for LinReg Using 5-Fold Cross Validation [alpha = 0.1, 1-mil iterations]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lin_batch, avg_mae, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.title('Average Mean Absolute Error vs Minibatch Size for LinReg Using 5-Fold Cross Validation [alpha = 0.1, 1-mil iterations]')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqQLMNemZeYY"
      },
      "outputs": [],
      "source": [
        "log_batch = [8, 16, 32, 64, 100]\n",
        "avg_time = [1.6673, 2.6888, 6.2756, 14.5517, 11.0571]\n",
        "avg_it = [20605.4, 35887.6, 81325.8, 162469.4, 113049.4]\n",
        "avg_acc = [92.2857, 97.1429, 98.3577, 96.4286, 96.4286]\n",
        "avg_f1 = [95.9769, 97.4982, 98.3577, 96.7768, 96.2748]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_batch, avg_time, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('Average Time [s]')\n",
        "plt.title('Average Training Time vs Minibatch Size for LogReg Using 5 Fold Cross Validation [alpha = 0.1]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_batch, avg_it, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('Number of Iterations')\n",
        "plt.title('Average Number of Iterations vs Minibatch Size for LogReg Using 5 Fold Cross Validation [alpha = 0.1]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_batch, avg_acc, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('Accuracy [%]')\n",
        "plt.title('Average Accuracy vs Minibatch Size for LogReg Using 5 Fold Cross Validation [alpha = 0.1]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_batch, avg_acc, marker='o')\n",
        "plt.xlabel('Minibatch Size')\n",
        "plt.ylabel('F1-Score [%]')\n",
        "plt.title('Average F1-Score vs Minibatch Size for LogReg Using 5 Fold Cross Validation [alpha = 0.1]')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KefAMwhuG26E"
      },
      "source": [
        "###3.5 Performance by Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deXgd1d4KO0K"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvgoWF-kObK8"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq5LfQiqOeue"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPH4Q3WrZpbF"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhMjkwX4TDCi"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XHw6VQLOfqB"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUvsxhGBehne"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHkpquet6sod"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXENUEM86tNo"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXCLuPv_6uOi"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tPWNujd6uBB"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaLHLgKO7CCS"
      },
      "outputs": [],
      "source": [
        "logistic_validation(wine_norm2, 32, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSdOVJuU7EQQ"
      },
      "outputs": [],
      "source": [
        "lin_rate = [0.001, 0.01, 0.1, 0.3]\n",
        "avg_time = [76.9206, 76.9592, 76.3572, 76.6099]\n",
        "avg_mse = [26.0058, 25.9265, 27.6081, 27.5346]\n",
        "avg_mae = [3.5320, 3.5461, 3.6831, 3.7256]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lin_rate, avg_time, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Average Time [s]')\n",
        "plt.title('Average Training Time vs Learning Rate for LinReg Using 5-Fold Cross Validation [Batch size 32, 1-mil iterations]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lin_rate, avg_mse, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Average Mean Squared Error vs Learning Rate for LinReg Using 5-Fold Cross Validation [Batch size 32, 1-mil iterations]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lin_rate, avg_mae, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.title('Average Mean Absolute Error vs Learning Rate for LinReg Using 5-Fold Cross Validation [Batch size 32, 1-mil iterations]')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhyaT_cn7PfP"
      },
      "outputs": [],
      "source": [
        "log_rate = [0.001, 0.01, 0.1, 0.3, 0.5, 1]\n",
        "avg_time = [86.5277, 68.2587, 7.3904, 2.9644, 2.2222, 1.4787]\n",
        "avg_it = [1000000, 793539.8, 84408.4, 35273, 25315.2, 37052]\n",
        "avg_acc = [95.7142, 97.1429, 96.4286, 97.1428, 97.1429, 97.1429]\n",
        "avg_f1 = [96.0069, 97.3593, 96.3480, 97.6327, 95.5780, 97.6433]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_rate, avg_time, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Average Time [s]')\n",
        "plt.title('Average Training Time vs Learning Rate for LogReg Using 5 Fold Cross Validation [Batch size 32]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_rate, avg_it, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Number of Iterations')\n",
        "plt.title('Average Number of iterations vs Learning Rate for LogReg Using 5 Fold Cross Validation [Batch size 32]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_rate, avg_acc, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Accuracy [%]')\n",
        "plt.title('Average Accuracy vs Learning Rate for LogReg Using 5 Fold Cross Validation [Batch size 32]')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(log_rate, avg_acc, marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('F1-Score [%]')\n",
        "plt.title('Average F1-Score vs Learning Rate for LogReg Using 5 Fold Cross Validation [Batch size 32]')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqggi_xw6DAY"
      },
      "source": [
        "### 3.7 Gaussian Basis Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peyOQKrU6FuD"
      },
      "outputs": [],
      "source": [
        "#housing_norm1 (normalized data using standardization)\n",
        "# 5 features will be : crime (1), rooms (6), dis (8), Tax (10), ptratio (11)  because they seem to have the most influence logically\n",
        "\n",
        "\n",
        "def Gaus(X):\n",
        "  index = random.randint(0, X.shape[0]//5*4)  # The 0.8 makes sure its in the training set\n",
        "  u = X[index]  # Randomly selected center\n",
        "  phi = np.exp(-1/2*(X-u)**2)\n",
        "  return (phi)\n",
        "\n",
        "crime = Gaus(housing_norm1[:, 0])\n",
        "rooms = Gaus(housing_norm1[:, 5])\n",
        "dis = Gaus(housing_norm1[:, 7])\n",
        "tax = Gaus(housing_norm1[:, 9])\n",
        "ptratio = Gaus(housing_norm1[:, 10])\n",
        "\n",
        "n = housing_norm1.shape[0]\n",
        "\n",
        "gaus_data = np.hstack(( crime.reshape(n, 1), rooms.reshape(n, 1), dis.reshape(n, 1), tax.reshape(n, 1), ptratio.reshape(n, 1) ))\n",
        "gaus_data.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u-FKUMD6LBe"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Gauss_Reg():\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.Y = data[:, -1]\n",
        "    self.N = data.shape[0]\n",
        "    self.n = self.N//5*4\n",
        "    self.train_data = data[:self.n]\n",
        "    self.test_data = data[self.n:]\n",
        "\n",
        "  def gaus_data(self, X = None, include = True):\n",
        "    # The purpose of this function is simply to add the gaussian basis data to the dataset.\n",
        "    if X != None:\n",
        "      crime = Gaus(X[:, 0])\n",
        "      rooms = Gaus(X[:, 5])\n",
        "      dis = Gaus(X[:, 7])\n",
        "      tax = Gaus(X[:, 9])\n",
        "      ptratio = Gaus(X[:, 10])\n",
        "\n",
        "    # Columns used for the Gaussian Basis\n",
        "    crime = Gaus(self.data[:, 0])\n",
        "    rooms = Gaus(self.data[:, 5])\n",
        "    dis = Gaus(self.data[:, 7])\n",
        "    tax = Gaus(self.data[:, 9])\n",
        "    ptratio = Gaus(self.data[:, 10])\n",
        "\n",
        "    self.g_data = np.hstack(( crime.reshape(self.N, 1), rooms.reshape(self.N, 1), dis.reshape(self.N, 1), tax.reshape(self.N, 1), ptratio.reshape(self.N, 1) ))\n",
        "    # The include was added to compare the accuracy of a model using only the gaussian basis (5 features)\n",
        "    # with a model that adds the gaussian basis to the original dataset (18 features)\n",
        "    if include == True:\n",
        "      self.data = np.hstack((self.g_data, self.data))\n",
        "    else:\n",
        "      self.data = np.hstack((self.g_data, self.Y.reshape(self.N, 1)))\n",
        "    #return(self.g_data)\n",
        "\n",
        "  def fit(self):\n",
        "    training_set = self.data[:self.n]\n",
        "\n",
        "    X = bias(training_set[:, :-1])\n",
        "    Y = training_set[:, -1]\n",
        "\n",
        "    start_time = time.time()\n",
        "    self.w = np.linalg.solve(X.T@X,X.T@Y) # From linear Regression notes, X.T@X@w = X.T@Y which is in the form Aw = b, use linalg to solve it so we avoid taking the inverse\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"[Gauss + Feature] Training time: {elapsed_time} seconds.\\n\")\n",
        "\n",
        "\n",
        "  def predict(self, new_test_set = None):\n",
        "    if new_test_set.any() == None:\n",
        "      X = bias(self.data[self.n:, :-1])\n",
        "    else:\n",
        "      X = bias()\n",
        "    yh = np.dot(X, self.w)\n",
        "    return (yh)\n",
        "\n",
        "  def target(self):\n",
        "    return(self.data[self.n:,-1])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8gLzGXH9Qv4"
      },
      "outputs": [],
      "source": [
        "gaus_model = Gauss_Reg(housing_norm1)\n",
        "gaus_model.gaus_data()\n",
        "gaus_model.fit()\n",
        "gauss_predictions = gaus_model.predict()\n",
        "true_vals = gaus_model.target()\n",
        "\n",
        "N = housing_norm1.shape[0]\n",
        "test_data = housing_norm1[N//5*4:]\n",
        "\n",
        "lin_model = LinReg(housing_norm1)\n",
        "\n",
        "w = lin_model.fit()\n",
        "lin__prediction = lin_model.predict(test_data, w)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrQX1v7MC3Fi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create a table\n",
        "data = [[\"Metric\", \"Analytical (Train)\", \"Analytical (Test)\", \"GD (Train)\", \"GD (Test)\"],\n",
        "        [\"MAE\", analytical_mae_train, analytical_mae_test, gd_mae_train, gd_mae_test],\n",
        "        [\"MSE\", analytical_mse_train, analytical_mse_test, gd_mse_train, gd_mse_test],\n",
        "        [\"RMSE\", analytical_rmse_train, analytical_rmse_test, gd_rmse_train, gd_rmse_test]]\n",
        "\n",
        "table = tabulate(data, headers=\"firstrow\", tablefmt=\"fancy_grid\")\n",
        "\n",
        "# Print the table\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.arange(5)\n",
        "X = None\n",
        "if X.any() != None:\n",
        "  print('works')"
      ],
      "metadata": {
        "id": "fsWzGnOu-pVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN7hznirkyzE"
      },
      "source": [
        "###3.8 Analytical LinReg vs Mini-Batch SDG LinReg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqe6YeRslzUQ"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qX6jio-wl9Mn"
      },
      "outputs": [],
      "source": [
        "linear_validation(housing_norm2, 32, 0.1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}